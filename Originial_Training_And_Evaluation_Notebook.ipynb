{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb446164-9181-4534-b033-07ae0f1ca51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the necessary imports below\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471532b9-43f1-492c-a5fb-349490c2f561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# We are setting up the model, albert-base-v2, below specifically using SequenceClassification and id2label and label2id to go back and forth between labels and their encoding\n",
    "model_name = \"albert-base-v2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label={0: \"Non-Limerick\", 1: \"Limerick\"}, label2id={\"Non-Limerick\": 0, \"Limerick\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd4d0e2e-3190-48ce-b27c-d1e09ab9f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We prepare the dataset, tokenize the information, etc. below\n",
    "def prepare_dataset(poems, labels):\n",
    "    label_encoding = [1 if label == \"Limerick\" else 0 for label in labels]\n",
    "    return Dataset.from_dict({\"text\": [f\"Poem:\\n{p}\" for p, l in zip(poems, labels)], \"label\": label_encoding})\n",
    "\n",
    "def tokenize_function(examples, tokenizer, max_length=64):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    \n",
    "questions_df = pd.read_csv(\"Fine_Tuning_Assignment - Limerick Classification-2.csv\")\n",
    "\n",
    "dataset = prepare_dataset(questions_df[\"Input (Poem)\"], questions_df[\"Label (Limerick or Non-Limerick)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f51cb824-51e3-4079-b3ca-a34cc141d97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0586a6fb-bbf6-440a-98b3-8f3b476e91e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2faea79eb88b49ff8decc1f16b5480d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(lambda examples: tokenize_function(examples, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f754637-eeef-4bf1-84ef-1e117a4f1987",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = tokenized_dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8a943ea-d790-43f7-bbf4-88db51aaff74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 270\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb32ed44-3160-4485-b7c5-e54b21caa501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': \"Poem:\\nIf the Limerick's cocktail you 'd quaff,\\nStir nonsense with wit, each a half,\\nAdd a dash of good fun,\\nDrop in a pun-\\nAnd then make a noise like a laugh.\",\n",
       "  'label': 1},\n",
       " {'text': \"Poem:\\nIf the Limerick's cocktail you 'd quaff,\\nStir nonsense with wit, each a half,\\nAdd a dash of good fun,\\nDrop in a pun-\\nAnd then make a noise like a laugh.\",\n",
       "  'label': 1,\n",
       "  'input_ids': [2,\n",
       "   4629,\n",
       "   45,\n",
       "   100,\n",
       "   14,\n",
       "   18185,\n",
       "   22,\n",
       "   18,\n",
       "   18816,\n",
       "   42,\n",
       "   13,\n",
       "   22,\n",
       "   43,\n",
       "   7131,\n",
       "   2460,\n",
       "   15,\n",
       "   13216,\n",
       "   13,\n",
       "   16684,\n",
       "   29,\n",
       "   9642,\n",
       "   15,\n",
       "   206,\n",
       "   21,\n",
       "   519,\n",
       "   15,\n",
       "   3547,\n",
       "   21,\n",
       "   8405,\n",
       "   16,\n",
       "   254,\n",
       "   2414,\n",
       "   15,\n",
       "   2804,\n",
       "   19,\n",
       "   21,\n",
       "   11582,\n",
       "   8,\n",
       "   17,\n",
       "   94,\n",
       "   233,\n",
       "   21,\n",
       "   3406,\n",
       "   101,\n",
       "   21,\n",
       "   3051,\n",
       "   9,\n",
       "   3,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'attention_mask': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0], tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c88814-e5d6-4558-a744-6198836ad436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishnapalempalli/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "output_dir = \"./fine_tuned_albert\"\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab0ae90f-64bf-4906-b6a2-ba6e59a9902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute classification metrics (accuracy, precision, recall, and f1 using the evaluate library\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    all_logits, all_labels = predictions\n",
    "    final_predictions = all_logits.argmax(axis=-1)\n",
    "    accuracy_score = accuracy.compute(predictions=final_predictions, references=all_labels)\n",
    "    precision_score = precision.compute(predictions=final_predictions, references=all_labels, average=\"binary\")\n",
    "    recall_score = recall.compute(predictions=final_predictions, references=all_labels, average=\"binary\")\n",
    "    f1_score = f1.compute(predictions=final_predictions, references=all_labels, average=\"binary\")\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score[\"accuracy\"],\n",
    "        \"Precision\": precision_score[\"precision\"],\n",
    "        \"Recall\": recall_score[\"recall\"],\n",
    "        \"F1\": f1_score[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "011fe39a-2dab-4085-824e-c66415eda24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 00:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.717100</td>\n",
       "      <td>0.643103</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.650400</td>\n",
       "      <td>0.603371</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.592600</td>\n",
       "      <td>0.567159</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.475693</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.538800</td>\n",
       "      <td>0.524115</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.501200</td>\n",
       "      <td>0.520818</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>0.470920</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.523200</td>\n",
       "      <td>0.448080</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.729242</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.428400</td>\n",
       "      <td>0.414524</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.511400</td>\n",
       "      <td>0.430950</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.469421</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.424900</td>\n",
       "      <td>0.443961</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.435624</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>0.464821</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.296700</td>\n",
       "      <td>0.473888</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.471647</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.47164714336395264, 'eval_Accuracy': 0.8, 'eval_Precision': 0.7222222222222222, 'eval_Recall': 0.9285714285714286, 'eval_F1': 0.8125000000000001, 'eval_runtime': 0.1614, 'eval_samples_per_second': 185.822, 'eval_steps_per_second': 24.776, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# We initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test[\"train\"],\n",
    "    eval_dataset=train_test[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.can_return_loss = True\n",
    "\n",
    "# We start training\n",
    "trainer.train()\n",
    "\n",
    "# We save the trained model and evaluate the results\n",
    "trainer.save_model(\"./fine_tuned_albert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_albert\")\n",
    "\n",
    "test_results = trainer.evaluate()\n",
    "print(\"Test Results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef33e7a1-114e-43de-a6b7-057f8852d507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d9fe3871aa4a93a469f85e508b020a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics: {'test_loss': 0.7043936848640442, 'test_model_preparation_time': 0.0002, 'test_Accuracy': 0.4375, 'test_Precision': 0.4, 'test_Recall': 0.25, 'test_F1': 0.3076923076923077, 'test_runtime': 0.1447, 'test_samples_per_second': 110.598, 'test_steps_per_second': 13.825}\n",
      "\n",
      "Classification Predictions for Baseline Model:\n",
      "\n",
      "Poem:\n",
      "    A cannibal monarch imperial\n",
      "    Kept his wives on a diet of cereal,\n",
      "    But he didn't much care\n",
      "    What the women should wear,\n",
      "    Nor did they; it was quite immaterial.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a foppish old beau,\n",
      "    Who said, \"I find walking too sleau.\n",
      "    So I prances down the street\n",
      "    And throw out my feet\n",
      "    And trip my fantastical teau.\"\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a young maid from Japan\n",
      "    Who married a Hottentot man.\n",
      "    The girl she was yellow.\n",
      "    And black was the fellow.\n",
      "    And their children were all black and tan.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a poor fellow from Lynn,\n",
      "    By accident sat on a pynn,\n",
      "    He let out a shriek,\n",
      "    A howl and a squiek.\n",
      "    And his language was really a synn.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Professor, you should be commended\n",
      "    On your theory so geniusly splendid.\n",
      "    But some say it's luck,\n",
      "    And you really just suck,\n",
      "    'Cause your theory's not what you intended!\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a classical theory\n",
      "    Of which quantum disciples were leery.\n",
      "    They said, ‚ÄúWhy spend so long\n",
      "    On a theory that‚Äôs wrong?‚Äù\n",
      "    Well, it works for your everyday query!\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Consider, when seeking gestalts,\n",
      "    The theories that science exalts.\n",
      "    It's not that they're known\n",
      "    To be written in stone.\n",
      "    It's just that we can't say they're false.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    God's first tries were hardly ideal,\n",
      "    You see, complex worlds have no appeal.\n",
      "    In the present edition,\n",
      "    He made things Hermitian,\n",
      "    And this world, it seems, is quite real.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    We need to take care of the one world we live in!\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    In familiar bed,\n",
      "    hands reaching into the light.\n",
      "    Soul blossoms tonight.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    Prayers are good wishes\n",
      "    rising up to the realm of\n",
      "    possibilities.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Once more the storm is howling, and half hid\n",
      "    Under this cradle-hood and coverlid\n",
      "    My child sleeps on. There is no obstacle\n",
      "    But Gregory's wood and one bare hill\n",
      "    Whereby the haystack- and roof-levelling wind,\n",
      "    Bred on the Atlantic, can be stayed;\n",
      "    And for an hour I have walked and prayed\n",
      "    Because of the great gloom that is in my mind.\n",
      "    I have walked and prayed for this young child an hour\n",
      "    And heard the sea-wind scream upon the tower,\n",
      "    And under the arches of the bridge, and scream\n",
      "    In the elms above the flooded stream;\n",
      "    Imagining in excited reverie\n",
      "    That the future years had come,\n",
      "    Dancing to a frenzied drum,\n",
      "    Out of the murderous innocence of the sea.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    May she be granted beauty and yet not\n",
      "    Beauty to make a stranger's eye distraught,\n",
      "    Or hers before a looking-glass, for such,\n",
      "    Being made beautiful overmuch,\n",
      "    Consider beauty a sufficient end,\n",
      "    Lose natural kindness and maybe\n",
      "    The heart-revealing intimacy\n",
      "    That chooses right, and never find a friend.\n",
      "    Helen being chosen found life flat and dull\n",
      "    And later had much trouble from a fool,\n",
      "    While that great Queen, that rose out of the spray,\n",
      "    Being fatherless could have her way\n",
      "    Yet chose a bandy-legg√®d smith for man.\n",
      "    It's certain that fine women eat\n",
      "    A crazy salad with their meat\n",
      "    Whereby the Horn of Plenty is undone.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    A cannibal monarch\n",
      "    Kept his wives on a diet,\n",
      "    But he didn't much care\n",
      "    What the women should look like\n",
      "    Nor did they; it was quite immaterial.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a poor fellow,\n",
      "    By accident sat on a pynn,\n",
      "    He yelled out loud,\n",
      "    A howl and a squiek.\n",
      "    And his language was really a curse.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a\n",
      "    Of which quantum.\n",
      "    They said,\n",
      "    On a theory\n",
      "    Well, it works\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Model Metrics: {'test_loss': 0.371559202671051, 'test_model_preparation_time': 0.0002, 'test_Accuracy': 0.875, 'test_Precision': 0.8, 'test_Recall': 1.0, 'test_F1': 0.888888888888889, 'test_runtime': 0.0909, 'test_samples_per_second': 176.001, 'test_steps_per_second': 22.0}\n",
      "\n",
      "Classification Predictions for Fine-Tuned Model:\n",
      "\n",
      "Poem:\n",
      "    A cannibal monarch imperial\n",
      "    Kept his wives on a diet of cereal,\n",
      "    But he didn't much care\n",
      "    What the women should wear,\n",
      "    Nor did they; it was quite immaterial.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a foppish old beau,\n",
      "    Who said, \"I find walking too sleau.\n",
      "    So I prances down the street\n",
      "    And throw out my feet\n",
      "    And trip my fantastical teau.\"\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a young maid from Japan\n",
      "    Who married a Hottentot man.\n",
      "    The girl she was yellow.\n",
      "    And black was the fellow.\n",
      "    And their children were all black and tan.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a poor fellow from Lynn,\n",
      "    By accident sat on a pynn,\n",
      "    He let out a shriek,\n",
      "    A howl and a squiek.\n",
      "    And his language was really a synn.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    Professor, you should be commended\n",
      "    On your theory so geniusly splendid.\n",
      "    But some say it's luck,\n",
      "    And you really just suck,\n",
      "    'Cause your theory's not what you intended!\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a classical theory\n",
      "    Of which quantum disciples were leery.\n",
      "    They said, ‚ÄúWhy spend so long\n",
      "    On a theory that‚Äôs wrong?‚Äù\n",
      "    Well, it works for your everyday query!\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    Consider, when seeking gestalts,\n",
      "    The theories that science exalts.\n",
      "    It's not that they're known\n",
      "    To be written in stone.\n",
      "    It's just that we can't say they're false.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    God's first tries were hardly ideal,\n",
      "    You see, complex worlds have no appeal.\n",
      "    In the present edition,\n",
      "    He made things Hermitian,\n",
      "    And this world, it seems, is quite real.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    We need to take care of the one world we live in!\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    In familiar bed,\n",
      "    hands reaching into the light.\n",
      "    Soul blossoms tonight.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Prayers are good wishes\n",
      "    rising up to the realm of\n",
      "    possibilities.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Once more the storm is howling, and half hid\n",
      "    Under this cradle-hood and coverlid\n",
      "    My child sleeps on. There is no obstacle\n",
      "    But Gregory's wood and one bare hill\n",
      "    Whereby the haystack- and roof-levelling wind,\n",
      "    Bred on the Atlantic, can be stayed;\n",
      "    And for an hour I have walked and prayed\n",
      "    Because of the great gloom that is in my mind.\n",
      "    I have walked and prayed for this young child an hour\n",
      "    And heard the sea-wind scream upon the tower,\n",
      "    And under the arches of the bridge, and scream\n",
      "    In the elms above the flooded stream;\n",
      "    Imagining in excited reverie\n",
      "    That the future years had come,\n",
      "    Dancing to a frenzied drum,\n",
      "    Out of the murderous innocence of the sea.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    May she be granted beauty and yet not\n",
      "    Beauty to make a stranger's eye distraught,\n",
      "    Or hers before a looking-glass, for such,\n",
      "    Being made beautiful overmuch,\n",
      "    Consider beauty a sufficient end,\n",
      "    Lose natural kindness and maybe\n",
      "    The heart-revealing intimacy\n",
      "    That chooses right, and never find a friend.\n",
      "    Helen being chosen found life flat and dull\n",
      "    And later had much trouble from a fool,\n",
      "    While that great Queen, that rose out of the spray,\n",
      "    Being fatherless could have her way\n",
      "    Yet chose a bandy-legg√®d smith for man.\n",
      "    It's certain that fine women eat\n",
      "    A crazy salad with their meat\n",
      "    Whereby the Horn of Plenty is undone.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    A cannibal monarch\n",
      "    Kept his wives on a diet,\n",
      "    But he didn't much care\n",
      "    What the women should look like\n",
      "    Nor did they; it was quite immaterial.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a poor fellow,\n",
      "    By accident sat on a pynn,\n",
      "    He yelled out loud,\n",
      "    A howl and a squiek.\n",
      "    And his language was really a curse.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a\n",
      "    Of which quantum.\n",
      "    They said,\n",
      "    On a theory\n",
      "    Well, it works\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We are setting up the base version of the same model without the fine tuning for comparison purposes\n",
    "model_name = \"albert-base-v2\"\n",
    "finetuned_model_path = \"./fine_tuned_albert\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# We test the model on new examples that were not in our dataset\n",
    "new_test_examples = [\n",
    "    # Limerick\n",
    "    '''Poem:\n",
    "    A cannibal monarch imperial\n",
    "    Kept his wives on a diet of cereal,\n",
    "    But he didn't much care\n",
    "    What the women should wear,\n",
    "    Nor did they; it was quite immaterial.''',\n",
    "    # Limerick:\n",
    "    '''Poem:\n",
    "    There once was a foppish old beau,\n",
    "    Who said, \"I find walking too sleau.\n",
    "    So I prances down the street\n",
    "    And throw out my feet\n",
    "    And trip my fantastical teau.\"''',\n",
    "    # Limerick:\n",
    "    '''Poem:\n",
    "    There was a young maid from Japan\n",
    "    Who married a Hottentot man.\n",
    "    The girl she was yellow.\n",
    "    And black was the fellow.\n",
    "    And their children were all black and tan.''',\n",
    "    # Limerick:\n",
    "    '''Poem:\n",
    "    There was a poor fellow from Lynn,\n",
    "    By accident sat on a pynn,\n",
    "    He let out a shriek,\n",
    "    A howl and a squiek.\n",
    "    And his language was really a synn.''',\n",
    "    #Limerick\n",
    "    '''Poem:\n",
    "    Professor, you should be commended\n",
    "    On your theory so geniusly splendid.\n",
    "    But some say it's luck,\n",
    "    And you really just suck,\n",
    "    'Cause your theory's not what you intended!''',\n",
    "    # Limerick\n",
    "    '''Poem:\n",
    "    There once was a classical theory\n",
    "    Of which quantum disciples were leery.\n",
    "    They said, ‚ÄúWhy spend so long\n",
    "    On a theory that‚Äôs wrong?‚Äù\n",
    "    Well, it works for your everyday query!''',\n",
    "    # Limerick\n",
    "    '''Poem:\n",
    "    Consider, when seeking gestalts,\n",
    "    The theories that science exalts.\n",
    "    It's not that they're known\n",
    "    To be written in stone.\n",
    "    It's just that we can't say they're false.''',\n",
    "    # Limerick\n",
    "    '''Poem:\n",
    "    God's first tries were hardly ideal,\n",
    "    You see, complex worlds have no appeal.\n",
    "    In the present edition,\n",
    "    He made things Hermitian,\n",
    "    And this world, it seems, is quite real.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    We need to take care of the one world we live in!''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    In familiar bed,\n",
    "    hands reaching into the light.\n",
    "    Soul blossoms tonight.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    Prayers are good wishes\n",
    "    rising up to the realm of\n",
    "    possibilities.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    Once more the storm is howling, and half hid\n",
    "    Under this cradle-hood and coverlid\n",
    "    My child sleeps on. There is no obstacle\n",
    "    But Gregory's wood and one bare hill\n",
    "    Whereby the haystack- and roof-levelling wind,\n",
    "    Bred on the Atlantic, can be stayed;\n",
    "    And for an hour I have walked and prayed\n",
    "    Because of the great gloom that is in my mind.\n",
    "    I have walked and prayed for this young child an hour\n",
    "    And heard the sea-wind scream upon the tower,\n",
    "    And under the arches of the bridge, and scream\n",
    "    In the elms above the flooded stream;\n",
    "    Imagining in excited reverie\n",
    "    That the future years had come,\n",
    "    Dancing to a frenzied drum,\n",
    "    Out of the murderous innocence of the sea.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    May she be granted beauty and yet not\n",
    "    Beauty to make a stranger's eye distraught,\n",
    "    Or hers before a looking-glass, for such,\n",
    "    Being made beautiful overmuch,\n",
    "    Consider beauty a sufficient end,\n",
    "    Lose natural kindness and maybe\n",
    "    The heart-revealing intimacy\n",
    "    That chooses right, and never find a friend.\n",
    "    Helen being chosen found life flat and dull\n",
    "    And later had much trouble from a fool,\n",
    "    While that great Queen, that rose out of the spray,\n",
    "    Being fatherless could have her way\n",
    "    Yet chose a bandy-legg√®d smith for man.\n",
    "    It's certain that fine women eat\n",
    "    A crazy salad with their meat\n",
    "    Whereby the Horn of Plenty is undone.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    A cannibal monarch\n",
    "    Kept his wives on a diet,\n",
    "    But he didn't much care\n",
    "    What the women should look like\n",
    "    Nor did they; it was quite immaterial.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    There was a poor fellow,\n",
    "    By accident sat on a pynn,\n",
    "    He yelled out loud,\n",
    "    A howl and a squiek.\n",
    "    And his language was really a curse.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    There once was a\n",
    "    Of which quantum.\n",
    "    They said,\n",
    "    On a theory\n",
    "    Well, it works'''\n",
    "]\n",
    "# Below, 1 is a Limerick and 0 is a Non-Limerick\n",
    "new_test_labels = [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "new_test_dataset = Dataset.from_dict({\"text\": new_test_examples, \"label\": new_test_labels})\n",
    "\n",
    "new_token_test_dataset = new_test_dataset.map(lambda examples: tokenize_function(examples, tokenizer), batched=True)\n",
    "\n",
    "id2label = {0: \"Non-Limerick\", 1: \"Limerick\"}\n",
    "label2id = {\"Non-Limerick\": 0, \"Limerick\": 1}\n",
    "\n",
    "# Our baseline model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2label, label2id=label2id)\n",
    "base_trainer = Trainer(model=base_model, eval_dataset=new_token_test_dataset, compute_metrics=compute_metrics)\n",
    "\n",
    "# Our finetuned model\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(finetuned_model_path)\n",
    "finetuned_trainer = Trainer(model=finetuned_model, eval_dataset=new_token_test_dataset, compute_metrics=compute_metrics)\n",
    "\n",
    "# We print the results\n",
    "def print_results(trainer, model_name):\n",
    "    all_predictions = trainer.predict(new_token_test_dataset)\n",
    "    predicted_labels = torch.argmax(torch.tensor(all_predictions.predictions), axis=1).tolist()\n",
    "    \n",
    "    model_metrics = all_predictions.metrics\n",
    "    print(f\"{model_name} Model Metrics:\", model_metrics)\n",
    "\n",
    "    print(f\"\\nClassification Predictions for {model_name} Model:\\n\")\n",
    "    for example, true_label, pred_label in zip(new_test_examples, new_test_labels, predicted_labels):\n",
    "        print(f\"{example}\\n\\nTrue Label: {id2label[true_label]}\\n\\nPredicted Label: {id2label[pred_label]}\\n\")\n",
    "\n",
    "print_results(base_trainer, \"Baseline\")\n",
    "print_results(finetuned_trainer, \"Fine-Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c3169d1-162d-469e-872c-c4a8b9a51b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# We are setting up the model, google/electra-base-discriminator, below specifically using SequenceClassification and id2label and label2id to go back and forth between labels and their encoding\n",
    "model_name = \"google/electra-base-discriminator\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label={0: \"Non-Limerick\", 1: \"Limerick\"}, label2id={\"Non-Limerick\": 0, \"Limerick\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a85a7fa-ed26-4edd-9a7a-5dfc21573675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We prepare the dataset, tokenize the information, etc. below\n",
    "def prepare_dataset(poems, labels):\n",
    "    label_encoding = [1 if label == \"Limerick\" else 0 for label in labels]\n",
    "    return Dataset.from_dict({\"text\": [f\"Poem:\\n{p}\" for p, l in zip(poems, labels)], \"label\": label_encoding})\n",
    "\n",
    "def tokenize_function(examples, tokenizer, max_length=64):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length)\n",
    "    \n",
    "questions_df = pd.read_csv(\"Fine_Tuning_Assignment - Limerick Classification-2.csv\")\n",
    "\n",
    "dataset = prepare_dataset(questions_df[\"Input (Poem)\"], questions_df[\"Label (Limerick or Non-Limerick)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "47b41fa7-f350-4e0e-9f91-c8f9b7b6cb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 300\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5f68d2e-8ad2-478f-9db9-fc0a8176a83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee139db3a734729aa8c42218accb1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(lambda examples: tokenize_function(examples, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f0082f2a-3c56-4549-9bb8-6930c98f8950",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test = tokenized_dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3866dbac-2e4d-4fde-96b1-80dd2156c63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 270\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 30\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bf2f53d4-f491-4fc5-88ea-e2bfbd2983a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': \"Poem:\\nIf the Limerick's cocktail you 'd quaff,\\nStir nonsense with wit, each a half,\\nAdd a dash of good fun,\\nDrop in a pun-\\nAnd then make a noise like a laugh.\",\n",
       "  'label': 1},\n",
       " {'text': \"Poem:\\nIf the Limerick's cocktail you 'd quaff,\\nStir nonsense with wit, each a half,\\nAdd a dash of good fun,\\nDrop in a pun-\\nAnd then make a noise like a laugh.\",\n",
       "  'label': 1,\n",
       "  'input_ids': [101,\n",
       "   5961,\n",
       "   1024,\n",
       "   2065,\n",
       "   1996,\n",
       "   15679,\n",
       "   1005,\n",
       "   1055,\n",
       "   18901,\n",
       "   2017,\n",
       "   1005,\n",
       "   1040,\n",
       "   24209,\n",
       "   10354,\n",
       "   2546,\n",
       "   1010,\n",
       "   16130,\n",
       "   14652,\n",
       "   2007,\n",
       "   15966,\n",
       "   1010,\n",
       "   2169,\n",
       "   1037,\n",
       "   2431,\n",
       "   1010,\n",
       "   5587,\n",
       "   1037,\n",
       "   11454,\n",
       "   1997,\n",
       "   2204,\n",
       "   4569,\n",
       "   1010,\n",
       "   4530,\n",
       "   1999,\n",
       "   1037,\n",
       "   26136,\n",
       "   1011,\n",
       "   1998,\n",
       "   2059,\n",
       "   2191,\n",
       "   1037,\n",
       "   5005,\n",
       "   2066,\n",
       "   1037,\n",
       "   4756,\n",
       "   1012,\n",
       "   102,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'token_type_ids': [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  'attention_mask': [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0], tokenized_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b07fcf2e-5e82-41c0-b94a-6f817f433e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krishnapalempalli/anaconda3/lib/python3.11/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define training arguments\n",
    "output_dir = \"./fine_tuned_electra_5\"\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2eb63733-cfb7-4724-a588-6a99b6904c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute classification metrics (accuracy, precision, recall, and f1 using the evaluate library\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(predictions):\n",
    "    all_logits, all_labels = predictions\n",
    "    final_predictions = all_logits.argmax(axis=-1)\n",
    "    accuracy_score = accuracy.compute(predictions=final_predictions, references=all_labels)\n",
    "    precision_score = precision.compute(predictions=final_predictions, references=all_labels, average=\"binary\")\n",
    "    recall_score = recall.compute(predictions=final_predictions, references=all_labels, average=\"binary\")\n",
    "    f1_score = f1.compute(predictions=final_predictions, references=all_labels, average=\"binary\")\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score[\"accuracy\"],\n",
    "        \"Precision\": precision_score[\"precision\"],\n",
    "        \"Recall\": recall_score[\"recall\"],\n",
    "        \"F1\": f1_score[\"f1\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "794dcd87-e88a-4d23-8f18-2e4a99ffef08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [170/170 01:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>0.687751</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.686500</td>\n",
       "      <td>0.684370</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.680296</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.647900</td>\n",
       "      <td>0.660673</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.646870</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.595700</td>\n",
       "      <td>0.638431</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.600800</td>\n",
       "      <td>0.652733</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.523700</td>\n",
       "      <td>0.614580</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.522300</td>\n",
       "      <td>0.606350</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.546600</td>\n",
       "      <td>0.629916</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.633056</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.482400</td>\n",
       "      <td>0.652187</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.665750</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.657838</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.449800</td>\n",
       "      <td>0.639748</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.444200</td>\n",
       "      <td>0.634845</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>0.636441</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results: {'eval_loss': 0.6364413499832153, 'eval_Accuracy': 0.6666666666666666, 'eval_Precision': 0.631578947368421, 'eval_Recall': 0.8, 'eval_F1': 0.7058823529411765, 'eval_runtime': 0.1988, 'eval_samples_per_second': 150.912, 'eval_steps_per_second': 20.122, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "# We initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_test[\"train\"],\n",
    "    eval_dataset=train_test[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.can_return_loss = True\n",
    "\n",
    "# We start training\n",
    "trainer.train()\n",
    "\n",
    "# We save the trained model and evaluate the results\n",
    "trainer.save_model(\"./fine_tuned_electra_5\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_electra_5\")\n",
    "\n",
    "test_results = trainer.evaluate()\n",
    "print(\"Test Results:\", test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7d20d893-8cc1-475d-bb5b-45dbbd9790d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05fc32f64ca24375ae9900b196bd2776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-base-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Metrics: {'test_loss': 0.6812812685966492, 'test_model_preparation_time': 0.0011, 'test_Accuracy': 0.75, 'test_Precision': 1.0, 'test_Recall': 0.5, 'test_F1': 0.6666666666666666, 'test_runtime': 0.115, 'test_samples_per_second': 139.144, 'test_steps_per_second': 17.393}\n",
      "\n",
      "Classification Predictions for Baseline Model:\n",
      "\n",
      "Poem:\n",
      "    A cannibal monarch imperial\n",
      "    Kept his wives on a diet of cereal,\n",
      "    But he didn't much care\n",
      "    What the women should wear,\n",
      "    Nor did they; it was quite immaterial.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a foppish old beau,\n",
      "    Who said, \"I find walking too sleau.\n",
      "    So I prances down the street\n",
      "    And throw out my feet\n",
      "    And trip my fantastical teau.\"\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a young maid from Japan\n",
      "    Who married a Hottentot man.\n",
      "    The girl she was yellow.\n",
      "    And black was the fellow.\n",
      "    And their children were all black and tan.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a poor fellow from Lynn,\n",
      "    By accident sat on a pynn,\n",
      "    He let out a shriek,\n",
      "    A howl and a squiek.\n",
      "    And his language was really a synn.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    Professor, you should be commended\n",
      "    On your theory so geniusly splendid.\n",
      "    But some say it's luck,\n",
      "    And you really just suck,\n",
      "    'Cause your theory's not what you intended!\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a classical theory\n",
      "    Of which quantum disciples were leery.\n",
      "    They said, ‚ÄúWhy spend so long\n",
      "    On a theory that‚Äôs wrong?‚Äù\n",
      "    Well, it works for your everyday query!\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    Consider, when seeking gestalts,\n",
      "    The theories that science exalts.\n",
      "    It's not that they're known\n",
      "    To be written in stone.\n",
      "    It's just that we can't say they're false.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    God's first tries were hardly ideal,\n",
      "    You see, complex worlds have no appeal.\n",
      "    In the present edition,\n",
      "    He made things Hermitian,\n",
      "    And this world, it seems, is quite real.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    We need to take care of the one world we live in!\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    In familiar bed,\n",
      "    hands reaching into the light.\n",
      "    Soul blossoms tonight.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Prayers are good wishes\n",
      "    rising up to the realm of\n",
      "    possibilities.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Once more the storm is howling, and half hid\n",
      "    Under this cradle-hood and coverlid\n",
      "    My child sleeps on. There is no obstacle\n",
      "    But Gregory's wood and one bare hill\n",
      "    Whereby the haystack- and roof-levelling wind,\n",
      "    Bred on the Atlantic, can be stayed;\n",
      "    And for an hour I have walked and prayed\n",
      "    Because of the great gloom that is in my mind.\n",
      "    I have walked and prayed for this young child an hour\n",
      "    And heard the sea-wind scream upon the tower,\n",
      "    And under the arches of the bridge, and scream\n",
      "    In the elms above the flooded stream;\n",
      "    Imagining in excited reverie\n",
      "    That the future years had come,\n",
      "    Dancing to a frenzied drum,\n",
      "    Out of the murderous innocence of the sea.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    May she be granted beauty and yet not\n",
      "    Beauty to make a stranger's eye distraught,\n",
      "    Or hers before a looking-glass, for such,\n",
      "    Being made beautiful overmuch,\n",
      "    Consider beauty a sufficient end,\n",
      "    Lose natural kindness and maybe\n",
      "    The heart-revealing intimacy\n",
      "    That chooses right, and never find a friend.\n",
      "    Helen being chosen found life flat and dull\n",
      "    And later had much trouble from a fool,\n",
      "    While that great Queen, that rose out of the spray,\n",
      "    Being fatherless could have her way\n",
      "    Yet chose a bandy-legg√®d smith for man.\n",
      "    It's certain that fine women eat\n",
      "    A crazy salad with their meat\n",
      "    Whereby the Horn of Plenty is undone.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    A cannibal monarch\n",
      "    Kept his wives on a diet,\n",
      "    But he didn't much care\n",
      "    What the women should look like\n",
      "    Nor did they; it was quite immaterial.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a poor fellow,\n",
      "    By accident sat on a pynn,\n",
      "    He yelled out loud,\n",
      "    A howl and a squiek.\n",
      "    And his language was really a curse.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a\n",
      "    Of which quantum.\n",
      "    They said,\n",
      "    On a theory\n",
      "    Well, it works\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Model Metrics: {'test_loss': 0.47391584515571594, 'test_model_preparation_time': 0.0012, 'test_Accuracy': 0.75, 'test_Precision': 0.75, 'test_Recall': 0.75, 'test_F1': 0.75, 'test_runtime': 0.0754, 'test_samples_per_second': 212.272, 'test_steps_per_second': 26.534}\n",
      "\n",
      "Classification Predictions for Fine-Tuned Model:\n",
      "\n",
      "Poem:\n",
      "    A cannibal monarch imperial\n",
      "    Kept his wives on a diet of cereal,\n",
      "    But he didn't much care\n",
      "    What the women should wear,\n",
      "    Nor did they; it was quite immaterial.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a foppish old beau,\n",
      "    Who said, \"I find walking too sleau.\n",
      "    So I prances down the street\n",
      "    And throw out my feet\n",
      "    And trip my fantastical teau.\"\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a young maid from Japan\n",
      "    Who married a Hottentot man.\n",
      "    The girl she was yellow.\n",
      "    And black was the fellow.\n",
      "    And their children were all black and tan.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a poor fellow from Lynn,\n",
      "    By accident sat on a pynn,\n",
      "    He let out a shriek,\n",
      "    A howl and a squiek.\n",
      "    And his language was really a synn.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    Professor, you should be commended\n",
      "    On your theory so geniusly splendid.\n",
      "    But some say it's luck,\n",
      "    And you really just suck,\n",
      "    'Cause your theory's not what you intended!\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a classical theory\n",
      "    Of which quantum disciples were leery.\n",
      "    They said, ‚ÄúWhy spend so long\n",
      "    On a theory that‚Äôs wrong?‚Äù\n",
      "    Well, it works for your everyday query!\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Consider, when seeking gestalts,\n",
      "    The theories that science exalts.\n",
      "    It's not that they're known\n",
      "    To be written in stone.\n",
      "    It's just that we can't say they're false.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    God's first tries were hardly ideal,\n",
      "    You see, complex worlds have no appeal.\n",
      "    In the present edition,\n",
      "    He made things Hermitian,\n",
      "    And this world, it seems, is quite real.\n",
      "\n",
      "True Label: Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    We need to take care of the one world we live in!\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    In familiar bed,\n",
      "    hands reaching into the light.\n",
      "    Soul blossoms tonight.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Prayers are good wishes\n",
      "    rising up to the realm of\n",
      "    possibilities.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    Once more the storm is howling, and half hid\n",
      "    Under this cradle-hood and coverlid\n",
      "    My child sleeps on. There is no obstacle\n",
      "    But Gregory's wood and one bare hill\n",
      "    Whereby the haystack- and roof-levelling wind,\n",
      "    Bred on the Atlantic, can be stayed;\n",
      "    And for an hour I have walked and prayed\n",
      "    Because of the great gloom that is in my mind.\n",
      "    I have walked and prayed for this young child an hour\n",
      "    And heard the sea-wind scream upon the tower,\n",
      "    And under the arches of the bridge, and scream\n",
      "    In the elms above the flooded stream;\n",
      "    Imagining in excited reverie\n",
      "    That the future years had come,\n",
      "    Dancing to a frenzied drum,\n",
      "    Out of the murderous innocence of the sea.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    May she be granted beauty and yet not\n",
      "    Beauty to make a stranger's eye distraught,\n",
      "    Or hers before a looking-glass, for such,\n",
      "    Being made beautiful overmuch,\n",
      "    Consider beauty a sufficient end,\n",
      "    Lose natural kindness and maybe\n",
      "    The heart-revealing intimacy\n",
      "    That chooses right, and never find a friend.\n",
      "    Helen being chosen found life flat and dull\n",
      "    And later had much trouble from a fool,\n",
      "    While that great Queen, that rose out of the spray,\n",
      "    Being fatherless could have her way\n",
      "    Yet chose a bandy-legg√®d smith for man.\n",
      "    It's certain that fine women eat\n",
      "    A crazy salad with their meat\n",
      "    Whereby the Horn of Plenty is undone.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n",
      "Poem:\n",
      "    A cannibal monarch\n",
      "    Kept his wives on a diet,\n",
      "    But he didn't much care\n",
      "    What the women should look like\n",
      "    Nor did they; it was quite immaterial.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There was a poor fellow,\n",
      "    By accident sat on a pynn,\n",
      "    He yelled out loud,\n",
      "    A howl and a squiek.\n",
      "    And his language was really a curse.\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Limerick\n",
      "\n",
      "Poem:\n",
      "    There once was a\n",
      "    Of which quantum.\n",
      "    They said,\n",
      "    On a theory\n",
      "    Well, it works\n",
      "\n",
      "True Label: Non-Limerick\n",
      "\n",
      "Predicted Label: Non-Limerick\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We are setting up the base version of the same model without the fine tuning for comparison purposes\n",
    "model_name = \"google/electra-base-discriminator\"\n",
    "finetuned_model_path = \"./fine_tuned_electra_5\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# We test the model on new examples that were not in our dataset\n",
    "new_test_examples = [\n",
    "    # Limerick\n",
    "    '''Poem:\n",
    "    A cannibal monarch imperial\n",
    "    Kept his wives on a diet of cereal,\n",
    "    But he didn't much care\n",
    "    What the women should wear,\n",
    "    Nor did they; it was quite immaterial.''',\n",
    "    # Limerick:\n",
    "    '''Poem:\n",
    "    There once was a foppish old beau,\n",
    "    Who said, \"I find walking too sleau.\n",
    "    So I prances down the street\n",
    "    And throw out my feet\n",
    "    And trip my fantastical teau.\"''',\n",
    "    # Limerick:\n",
    "    '''Poem:\n",
    "    There was a young maid from Japan\n",
    "    Who married a Hottentot man.\n",
    "    The girl she was yellow.\n",
    "    And black was the fellow.\n",
    "    And their children were all black and tan.''',\n",
    "    # Limerick:\n",
    "    '''Poem:\n",
    "    There was a poor fellow from Lynn,\n",
    "    By accident sat on a pynn,\n",
    "    He let out a shriek,\n",
    "    A howl and a squiek.\n",
    "    And his language was really a synn.''',\n",
    "    #Limerick\n",
    "    '''Poem:\n",
    "    Professor, you should be commended\n",
    "    On your theory so geniusly splendid.\n",
    "    But some say it's luck,\n",
    "    And you really just suck,\n",
    "    'Cause your theory's not what you intended!''',\n",
    "    # Limerick\n",
    "    '''Poem:\n",
    "    There once was a classical theory\n",
    "    Of which quantum disciples were leery.\n",
    "    They said, ‚ÄúWhy spend so long\n",
    "    On a theory that‚Äôs wrong?‚Äù\n",
    "    Well, it works for your everyday query!''',\n",
    "    # Limerick\n",
    "    '''Poem:\n",
    "    Consider, when seeking gestalts,\n",
    "    The theories that science exalts.\n",
    "    It's not that they're known\n",
    "    To be written in stone.\n",
    "    It's just that we can't say they're false.''',\n",
    "    # Limerick\n",
    "    '''Poem:\n",
    "    God's first tries were hardly ideal,\n",
    "    You see, complex worlds have no appeal.\n",
    "    In the present edition,\n",
    "    He made things Hermitian,\n",
    "    And this world, it seems, is quite real.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    We need to take care of the one world we live in!''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    In familiar bed,\n",
    "    hands reaching into the light.\n",
    "    Soul blossoms tonight.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    Prayers are good wishes\n",
    "    rising up to the realm of\n",
    "    possibilities.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    Once more the storm is howling, and half hid\n",
    "    Under this cradle-hood and coverlid\n",
    "    My child sleeps on. There is no obstacle\n",
    "    But Gregory's wood and one bare hill\n",
    "    Whereby the haystack- and roof-levelling wind,\n",
    "    Bred on the Atlantic, can be stayed;\n",
    "    And for an hour I have walked and prayed\n",
    "    Because of the great gloom that is in my mind.\n",
    "    I have walked and prayed for this young child an hour\n",
    "    And heard the sea-wind scream upon the tower,\n",
    "    And under the arches of the bridge, and scream\n",
    "    In the elms above the flooded stream;\n",
    "    Imagining in excited reverie\n",
    "    That the future years had come,\n",
    "    Dancing to a frenzied drum,\n",
    "    Out of the murderous innocence of the sea.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    May she be granted beauty and yet not\n",
    "    Beauty to make a stranger's eye distraught,\n",
    "    Or hers before a looking-glass, for such,\n",
    "    Being made beautiful overmuch,\n",
    "    Consider beauty a sufficient end,\n",
    "    Lose natural kindness and maybe\n",
    "    The heart-revealing intimacy\n",
    "    That chooses right, and never find a friend.\n",
    "    Helen being chosen found life flat and dull\n",
    "    And later had much trouble from a fool,\n",
    "    While that great Queen, that rose out of the spray,\n",
    "    Being fatherless could have her way\n",
    "    Yet chose a bandy-legg√®d smith for man.\n",
    "    It's certain that fine women eat\n",
    "    A crazy salad with their meat\n",
    "    Whereby the Horn of Plenty is undone.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    A cannibal monarch\n",
    "    Kept his wives on a diet,\n",
    "    But he didn't much care\n",
    "    What the women should look like\n",
    "    Nor did they; it was quite immaterial.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    There was a poor fellow,\n",
    "    By accident sat on a pynn,\n",
    "    He yelled out loud,\n",
    "    A howl and a squiek.\n",
    "    And his language was really a curse.''',\n",
    "    # Non-Limerick\n",
    "    '''Poem:\n",
    "    There once was a\n",
    "    Of which quantum.\n",
    "    They said,\n",
    "    On a theory\n",
    "    Well, it works'''\n",
    "]\n",
    "# Below, 1 is a Limerick and 0 is a Non-Limerick\n",
    "new_test_labels = [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "new_test_dataset = Dataset.from_dict({\"text\": new_test_examples, \"label\": new_test_labels})\n",
    "\n",
    "new_token_test_dataset = new_test_dataset.map(lambda examples: tokenize_function(examples, tokenizer), batched=True)\n",
    "\n",
    "id2label = {0: \"Non-Limerick\", 1: \"Limerick\"}\n",
    "label2id = {\"Non-Limerick\": 0, \"Limerick\": 1}\n",
    "\n",
    "# Our baseline model\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, id2label=id2label, label2id=label2id)\n",
    "base_trainer = Trainer(model=base_model, eval_dataset=new_token_test_dataset, compute_metrics=compute_metrics)\n",
    "\n",
    "# Our finetuned model\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(finetuned_model_path)\n",
    "finetuned_trainer = Trainer(model=finetuned_model, eval_dataset=new_token_test_dataset, compute_metrics=compute_metrics)\n",
    "\n",
    "# We print the results\n",
    "def print_results(trainer, model_name):\n",
    "    all_predictions = trainer.predict(new_token_test_dataset)\n",
    "    predicted_labels = torch.argmax(torch.tensor(all_predictions.predictions), axis=1).tolist()\n",
    "    \n",
    "    model_metrics = all_predictions.metrics\n",
    "    print(f\"{model_name} Model Metrics:\", model_metrics)\n",
    "\n",
    "    print(f\"\\nClassification Predictions for {model_name} Model:\\n\")\n",
    "    for example, true_label, pred_label in zip(new_test_examples, new_test_labels, predicted_labels):\n",
    "        print(f\"{example}\\n\\nTrue Label: {id2label[true_label]}\\n\\nPredicted Label: {id2label[pred_label]}\\n\")\n",
    "\n",
    "print_results(base_trainer, \"Baseline\")\n",
    "print_results(finetuned_trainer, \"Fine-Tuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674787ff-78ab-438d-a8cb-9a57dc4ae570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
